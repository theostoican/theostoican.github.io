<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Lagrangian | Theodor  Stoican</title>
    <meta name="author" content="Theodor  Stoican">
    <meta name="description" content="A blog for ML-dedicated material and personal thoughts. Disclaimer: Opinions are my own.
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://theostoican.github.io/blog/2022/lagrangian/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Theodor </span>Stoican</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Lagrangian</h1>
    <p class="post-meta">May 28, 2022</p>
    <p class="post-tags">
      <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
        ·  
        <a href="/blog/category/lagrangian">
          <i class="fas fa-tag fa-sm"></i> Lagrangian</a>  
          <a href="/blog/category/multipliers">
          <i class="fas fa-tag fa-sm"></i> multipliers</a>  
          <a href="/blog/category/and">
          <i class="fas fa-tag fa-sm"></i> and</a>  
          <a href="/blog/category/the">
          <i class="fas fa-tag fa-sm"></i> the</a>  
          <a href="/blog/category/basic-ml">
          <i class="fas fa-tag fa-sm"></i> basic-ml</a>  
          

    </p>
  </header>

  <article class="post-content">
    <h1 id="introduction">Introduction</h1>

<p>In machine learning, it is often the case that one ends up (after various modeling steps) with an optimization problem. For instance, in SVMs, one has to find the optimal hyperplane that maximizes the margin. Furthermore, optimization is generally potentially complicated due to constrains that one imposes on the optimal point that is to be found. According to the taxonomy of optimization problems, this type of problems is part of the class of <em>constrained optimization</em> problems. If the objective function that one wants to optimize (and typically minimize) is convex, there are two major techniques that are typically used in order to achieve this.</p>

<h1 id="the-lagrange-multipliers">The Lagrange multipliers</h1>

<p>Let us assume we have a convex objective function $ f(x) $ that we want to optimize (in particular, we will talk about minimization, since any maximization problem can be reduced to a minimization problem). Furthermore, there are a couple of additional constraints that we may want to impose on the minimum that we find. For now we will just focus on affine and equality constraints, since the method that we are going to investigate offers guarantees only for this class of constraints. To sum up, the problem that we’re looking at is of the form:</p>

<p>$ \min_{x \in Dom(f)} f(x) $
$ g_i(x) = 0 \forall i \in {1..n} $</p>

<p>, where $ f(x) $ - convex and $g_i(x)$ - affine constraints.</p>

<h2 id="intuition">Intuition</h2>

<p>Let us assume we want to optimize $f(x)$ without any constraints. To do this, one naturally looks at the gradient. We can just enforce $\nabla f(x) = 0$ and we find the $x$ at which this holds (assuming the function is convex). With the constraints, however, this idea does not work anymore, since the minimum of $f(x)$ may not fulfil $g_i(x) = 0$ for some $i$. Geometrically, in order to visualize this, let us assume (without loss of generality) we have only one constraint.</p>

<div style="text-align: center;">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/lagrangian/min_f_not_constrained_min-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/lagrangian/min_f_not_constrained_min-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/lagrangian/min_f_not_constrained_min-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/lagrangian/min_f_not_constrained_min.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

An example where the minimum of an objective function is not identical to the constrained minimum. Made with © Desmos.
</div>

<p>As we can see in the picture from above, the constrained minimum does not coincide with the minimum of $f$ and it is actually materialized at $x_{min} = (-0.63, 0.38)$. This is a bit to the left of the minimum of $f$. And, more importantly, $\nabla f(x_{min})$ is not $0$. To find this type of points analytically, Lagrange figured out that, instead of looking at where the gradient is 0, one should look instead at where the gradients of the constraint function and the objective function are parallel. This intuition is very revealing, due to the fact that the set of points among which we’re searching our minimum must be the set of points on the constraint line. If we take a certain point on a line and there exists another point that leads to a better minimum on the same line, then the gradient of $f$ must point towards to it. Therefore, it cannot be perpendicular on the tangent line to the curve at this point. Meanwhile, the gradient of the constraint function is always perpendicular on the line (one can also visualize it as the normal vector of the line). Similarly, if there is no other point better than the current point, then the gradient of $f$ must be perpendicular on the tangent (there is no better minimum on the constraint line, but there is one potentially outside of it - however, we are not interested in it). But since this point is on the constraint line, the gradient of $g$ (the constraint function) must also be perpendicular on the constraint line (and on the tangent, by extension). Therefore, by ensuring that the two gradients are parallel, we are sure that there cannot be a more optimal point than this. This can be visualized as follows:</p>

<div style="text-align: center;">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/lagrangian/LagrangeMultipliers2D-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/lagrangian/LagrangeMultipliers2D-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/lagrangian/LagrangeMultipliers2D-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/lagrangian/LagrangeMultipliers2D.png" class="img-fluid rounded z-depth-1 w-50" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

An example of Lagrange multipliers for 2D objective and constraints functions (© https://en.wikipedia.org/wiki/Lagrange_multiplier).
</div>

<h2 id="formalism">Formalism</h2>

<p>Analytically, this parallelism can also be described with the following equation:</p>

\[\nabla f(x) = \lambda \nabla g(x)\]

\[g(x) = 0\]

<p>$\lambda$ is a scalar that ensure that the vector gradients have the same direction, but not necessarily the same length. The second equation ensures that the point is on the constraint line. By solving this equation, one can find both the optimal $x$ and $\lambda$. This can also be naturally extended to multiple constraints $g_i(x)$, $\forall i \in {1..N}$.</p>

<h1 id="the-lagrangian">The Lagrangian</h1>

<h2 id="justification">Justification</h2>

<p>Problems in practice can be even more complex than this. In particular, one can find optimization problems, for which the contraint functions can be inequalities. For these situations, an extension of the method would be required. To understand why, let us have a look at the following example. Assume we have an objective function $f(x)=x^2$ with one constraint $2 \cdot x \leq 1$ (without loss of generalization we treat these constraints; constraints of the type $c(x) \geq a$ can be reformulated into $c’(x) \leq -a$, where $c’(x)=-c(x)$), which can be rephrased as follows:</p>

<p>$f(x) = x^2$
$g(x) \leq 0$</p>

<p>In the equations, I have rewritten the constraint as $g(x) = 2 \cdot x - 1$. Let us have a look at the graph of these functions.</p>

<div style="text-align: center;">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/lagrangian/example_ineq_constaint-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/lagrangian/example_ineq_constaint-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/lagrangian/example_ineq_constaint-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/lagrangian/example_ineq_constaint.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

An example of optimization problem where the optimal solution is different for inequality constraints, compared to equality constraints. Made with © Desmos.
</div>

<p>If one looks at the chart from above, one sees that the minimum of the problem with an inequality constraint does not coincide with the minimum for the problem with an equality constraint. By imposing $g(x) = 0$, the method of Lagrange multipliers would find the minimum on the constraint line. However, that does not coincide with the real optimum, which is actually the same as the minimum of $f(x)$. For this reason, an adaptation of the method of Lagrange multipliers is required in order to make it work for inequality constraints.</p>

<h2 id="intuition-1">Intuition</h2>

<p>One can also see the finding of an optimum under inequality constraints from a different angle. One could engineer a surrogate function that penalizes the points for which the inequality constraints do not hold. This can be mathematically translated as follows:</p>

<p>$ L(x, \lambda) = f(x) + \lambda \cdot g(x)$</p>

<p>This function that we just defined is called the Lagrangian. It is essentially a reformulation of the method of Lagrange multipliers for equality constraints that I described above. Its mechanics can be best understood when we look at it for $\lambda \gt 0$. $g(x)$ is always positive for points that do not fulfill the constraint. Hence, $\lambda \cdot g(x)$ will add a penalty to points outside of the constraint. Conversely, $\lambda \cdot g(x)$ will be negative for points that fulfil the constraint, since $g(x) \lt 0$. This leads to lowering the value of $L(x, \lambda)$ for points that overfulfil the constraint ($g(x) \lt \lt 0$).</p>

<p>Now, to solve this problem, one has to find a $\lambda$, which is big enough to penalize all the points that do not fulfill the constraint, but which also does not overly reward points that “overfit” on the constraint, i.e. points for which $g(x) \lt \lt 0$.</p>

<h2 id="formalism-1">Formalism</h2>

<p>Analytically, this can be phrased as finding $\min_{x} f(x) + \lambda g(x)$ for every possible $\lambda$ (which can be formulated as $g(\lambda) = \min_{x} f(x) + \lambda g(x)$) and then optimizing over $\lambda$, by finding $\max_{\lambda} g(\lambda)$. Optimizing $g$ is called, in literature, the dual problem. So, in a nutshell, finding the minimum under the constraints can be rephrased as:</p>

<p>$\max_{\lambda} \min{\x} L(x, \lambda)$</p>

<p>This also means finding the saddle point of the Lagrangian. To see why this works, let us look at an example. To keep things simple, we will look at an optimization problem with one inequality constraint only (without loss of generality):</p>

<p>$\min_{x} f(x)$
$g(x) = x+2 \lt 0$</p>

<p>The chart of this function would be:</p>

<div style="text-align: center;">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/lagrangian/lagrangian_simple_problem-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/lagrangian/lagrangian_simple_problem-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/lagrangian/lagrangian_simple_problem-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/lagrangian/lagrangian_simple_problem.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

An example of optimization problem where we have a convex objective and one inequality constraint. Made with © Desmos.
</div>

<p>The optimum that we’re interested in is at $x = -2$. Now, let us look at the dual function for certain values of $\lambda$.</p>

<div style="text-align: center;">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/lagrangian/lagrangian_multiple_lambda-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/lagrangian/lagrangian_multiple_lambda-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/lagrangian/lagrangian_multiple_lambda-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/lagrangian/lagrangian_multiple_lambda.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

The same problem from before, where we see the dual for multiple values of $\lambda$. Made with © Desmos.
</div>

<p>As one can see, the more we increase $\lambda$, the more the unconstrained minimum of $f$ (at $x=0$) is penalized. That is the reason why the constrained minimum ($g(\lambda)$) has to move to the left of the unconstrained minimum, so that it is closer to the constraint line. At the same time, the more we move to the left (up to a certain point as we will see), the larger the value of the constrained minimum (than the previous constrained minimum) is. This is due to the fact that we are in a regime where the first terms of $g$ is dominant ($f(x)$) and moving even slightly to the left entails moving farther from the unconstrained minimum of $f$ and thus having higher values for $f(x)$.</p>

<p>However, by going left farther and farther and entering the area where the constraint is fulfilled (see $\lambda=5$ in the figure from above), we enter a regime where the second term of $g$ is dominant ($\lambda g(x)$). This term is negative, since the constraint is fulfilled. By increasing $\lambda$, we only increase the influence of this term and thus generating smaller and smaller constrained minima (up to $-\inf$), that are far from what we are interested in.</p>

<p>The point we are actually interested in is at the intersection of the 2 regimes. $\lambda$ should be high enough such that all points to the right of the constraint line are sufficiently penalized and can not be optima anymore (the first term of $g$ is not overly influential), but small enough such that the points that are well into the constrained area are not overly appreciated (the second term of $g$ is not overly powerful). This point in which we are interested corresponds to $\lambda=4$ in the figure from above. It also corresponds to the point for which $g(x)=0$ (exactly on the edge of the constrained area). Finding this point corresponds to finding the maximum of $g$ and finding the maximum of $g$ entails solving $\max_{\lambda}\min_{x} L(x, \lambda), thus the saddle point of the Lagrangian.</p>

<p>This method, like the one of the Lagrange multipliers for equality constraints, can naturally be generalized to multiple constraints.</p>

<h2 id="guarantees">Guarantees</h2>

<p>Unfortunatelly, this algorithm does not necessarily provide theoretical guarantees for all class of problems. For instance, if the problem is not convex, then solving the dual will find a point that will be at a certain gap than the real optimum. The KKT conditions provide theoretical gurantees for the optima that are found, by defining (what is called in literature) <em>strong duality</em> (no gap between the optimum that is found and the real optimum) and the conditions to verify it for a specific problem.</p>

<h1 id="references">References</h1>

<p>[1] https://cs.stanford.edu/people/davidknowles/lagrangian_duality.pdf</p>

<p>[2] https://masszhou.github.io/2016/09/10/Lagrange-Duality/</p>

<p>[3] https://math.stackexchange.com/questions/223235/please-explain-the-intuition-behind-the-dual-problem-in-optimization</p>

  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/pca/">PCA</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/naive-bayes/">Naïve Bayes</a>
  </li>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Theodor  Stoican. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
